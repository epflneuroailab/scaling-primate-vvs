{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pickle\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.set_theme(style='ticks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = Path('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(repo_dir) not in sys.path:\n",
    "    sys.path.append(str(repo_dir))\n",
    "    \n",
    "from analysis.curve_fitting.src.fitting_functions import LOSS_FUNCTIONS\n",
    "from analysis.curve_fitting.src.utils import apply_filters, load_yaml, convert_loss_parameters, convert_loss_parameters_batch\n",
    "\n",
    "from visualization.src.utils import COLOR_PALETTES, set_ticks, save_figs, COLORS\n",
    "from visualization.src.visualize import plot_reg, plot_reg_bivariate, plot_confidence_intervals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'results_csv': repo_dir / 'results' / 'benchmark_scores.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_csv = args['results_csv']\n",
    "\n",
    "df_results = pd.read_csv(results_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\n",
    "    'data_filters': {\n",
    "        'set_filters': {\n",
    "            'region': [\n",
    "                'V1',\n",
    "                'V2',\n",
    "                'V4',\n",
    "                'IT',\n",
    "                'Behavioral'\n",
    "                ],\n",
    "            'dataset': [\n",
    "                'imagenet',\n",
    "                ],\n",
    "            'ssl_method': [\n",
    "                'simclr'\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "    'boolean_filters': {\n",
    "        'equals_false': [\n",
    "            'is_pretrained',\n",
    "            'is_random',\n",
    "            'is_adv',\n",
    "            'is_ablation'\n",
    "            ],\n",
    "        'equals_true': [\n",
    "            'is_ssl',\n",
    "            ]\n",
    "        },\n",
    "    \n",
    "    # 'group_by': {\n",
    "    #     'avg_score': {\n",
    "    #         'keys': [\n",
    "    #             'model_id',\n",
    "    #             'arch',\n",
    "    #             'dataset',\n",
    "    #             'flops',\n",
    "    #             'n_params',\n",
    "    #             'n_samples',\n",
    "    #             'n_samples_seen',\n",
    "    #             'total_flops',\n",
    "    #             'arch_family',\n",
    "    #             'samples_per_class',\n",
    "\n",
    "    #         ],\n",
    "    #         'reduce': {'score': 'mean'}}},\n",
    "\n",
    "    'combine_arch_families': True,\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = repo_dir / 'analysis'\n",
    "config_dir = analysis_dir / 'curve_fitting/configs/ssl/simclr'\n",
    "results_dir = analysis_dir / 'curve_fitting/outputs/fitting_results'\n",
    "# results_dir = analysis_dir / 'curve_fitting/outputs/fitting_results_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = [\n",
    "    'v1',\n",
    "    'v2',\n",
    "    'v4',\n",
    "    'it',\n",
    "    'behavior',\n",
    "    'avg',\n",
    "    'neuro'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_configs = {}\n",
    "\n",
    "for r in region:\n",
    "    yaml_config = config_dir / f'simclr_{r}.yaml'\n",
    "    all_configs[r] = load_yaml(yaml_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_fit_dict = {key: config['fitting_parameters']['loss_function'] for key, config in all_configs.items()}\n",
    "L_viz_dict = {key: config['visualization']['loss_function'] for key, config in all_configs.items()}\n",
    "x_scale_dict = {key: float(config['fitting_parameters']['X_scaler']) for key, config in all_configs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Data Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = {\n",
    "    name: apply_filters(df_results, config.get('data_filters', {}))\n",
    "    for name, config in all_configs.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_behavior = all_df['behavior']\n",
    "df_neuro = all_df['neuro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fitting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_params_dict = {}\n",
    "opt_params_boot_dict = {}\n",
    "\n",
    "for exp_name in all_configs.keys():\n",
    "    with open(results_dir / f'simclr_{exp_name}' / 'results.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "\n",
    "    L_fit = L_fit_dict[exp_name]\n",
    "    L_viz = L_viz_dict[exp_name]\n",
    "    optimized_params_dict[exp_name] = convert_loss_parameters(results['optimized_parameters'], L_fit, L_viz)\n",
    "\n",
    "    # Convert bootstrapped parameters\n",
    "    opt_params_boot = results['optimized_parameters_bootstrapped']\n",
    "    opt_params_boot_dict[exp_name] = convert_loss_parameters_batch(\n",
    "        params=opt_params_boot,\n",
    "        src_loss=L_fit,\n",
    "        dst_loss=L_viz\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_params_neuro = optimized_params_dict['neuro']\n",
    "opt_params_boot_neuro = opt_params_boot_dict['neuro']\n",
    "\n",
    "optimized_params_behavior = optimized_params_dict['behavior']\n",
    "opt_params_boot_behavior = opt_params_boot_dict['behavior']\n",
    "\n",
    "\n",
    "L = LOSS_FUNCTIONS[L_viz_dict['neuro']]\n",
    "x_scaler = x_scale_dict['neuro']\n",
    "X = df_neuro.total_flops.values / x_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_extend = 1.1\n",
    "x_extend = 10\n",
    "X_str = r'$$\\tilde{C}$$'\n",
    "linewidth = 3.0\n",
    "alpha_scatter = 1.0\n",
    "alpha_ci = 0.2\n",
    "alpha_fit = 1.0\n",
    "fig_multiplier = 0.7\n",
    "figsize = (12, 6)\n",
    "figsize = (10, 6)\n",
    "figsize = (fig_multiplier * figsize[0], fig_multiplier * figsize[1])\n",
    "\n",
    "\n",
    "color = COLORS['cyan_dark']\n",
    "color_palette = COLOR_PALETTES['samples']\n",
    "\n",
    "color_palaette = COLOR_PALETTES['regions']\n",
    "color_1, color_2 = color_palaette[0], color_palaette[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=figsize, dpi=300)\n",
    "ax = axes\n",
    "\n",
    "### Neuro\n",
    "df_region = df_neuro\n",
    "color = color_1\n",
    "sns.scatterplot(data=df_region, x='total_flops', y='score', ax=ax, color=color, alpha=alpha_scatter)\n",
    "plot_reg(X, optimized_params_neuro, L, ax, color=color, x_extend=x_extend, linestyle='-', X_str=X_str, x_scaler=x_scaler, show_x_scaler=False, linewidth=linewidth, legend=False, alpha=alpha_fit)\n",
    "plot_confidence_intervals(X, opt_params_boot_neuro, L, ax, color=color, x_scaler=x_scaler, x_extend=x_extend, percentile=95.0, invert_y=True, alpha=alpha_ci)\n",
    "\n",
    "### Behavioral\n",
    "df_region = df_behavior\n",
    "color = color_2\n",
    "sns.scatterplot(data=df_region, x='total_flops', y='score', ax=ax, color=color, alpha=alpha_scatter)\n",
    "plot_reg(X, optimized_params_behavior, L, ax, color=color, x_extend=x_extend, linestyle='-', X_str=X_str, invert_y=True, x_scaler=x_scaler, show_x_scaler=False, linewidth=linewidth, legend=False, alpha=alpha_fit)\n",
    "plot_confidence_intervals(X, opt_params_boot_behavior, L, ax, color=color, x_scaler=x_scaler, x_extend=x_extend, percentile=95.0, invert_y=True, alpha=alpha_ci)\n",
    "\n",
    "\n",
    "### Formatting\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('FLOPs')\n",
    "ax.set_ylabel('Alignment')\n",
    "ax.set_xlabel('Total Flops (C)', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Alignment Score (S)', fontsize=16, fontweight='bold')\n",
    "ax.set_title('SimCLR Training', fontsize=20, fontweight='bold')\n",
    "ax = set_ticks(ax, xticks_mode='log', yticks_mode=None, yticks=[0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "# ax.set_ylim(0, 0.6)\n",
    "# ax.grid(False)\n",
    "\n",
    "### Legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "labels = [\n",
    "    'Neural  Alignment\\n' + labels[0],\n",
    "    'Behavioral  Alignment\\n'  + labels[1]\n",
    "]\n",
    "l1 = ax.legend([handles[0]], [labels[0]], fontsize=12, loc='upper left')\n",
    "# l2 = ax.legend([handles[1]], [labels[1]], fontsize=12, loc='lower right')\n",
    "l2 = ax.legend([handles[1]], [labels[1]], fontsize=12, bbox_to_anchor=(0.6, 0.0), loc='lower right')\n",
    "ax.add_artist(l1)\n",
    "# ax.legend(handles, labels)\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "figures_dir = '../figures'\n",
    "fig_name = 'fig7_simclr'\n",
    "formats = ['pdf', 'png', 'svg']\n",
    "save_figs(figures_dir, fig_name, formats=formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=figsize, dpi=300)\n",
    "\n",
    "ax = axes\n",
    "\n",
    "### \n",
    "# df_plot = df.groupby(['model_id', 'total_flops', 'arch', 'n_samples', 'n_samples_seen', 'n_params', 'arch_family']).agg({'score':'mean'}).reset_index()\n",
    "df_plot = all_df['avg']\n",
    "L = LOSS_FUNCTIONS[L_viz_dict['avg']]\n",
    "x_scaler = x_scale_dict['avg']\n",
    "X = df_plot.total_flops.values / x_scaler\n",
    "optimized_params = optimized_params_dict['avg']\n",
    "opt_params_boot = opt_params_boot_dict['avg']\n",
    "\n",
    "\n",
    "sns.scatterplot(data=df_plot, x='total_flops', y='score', style='arch_family', size='n_params', hue='n_samples_seen', ax=ax, hue_norm=LogNorm(), size_norm=LogNorm(), palette=color_palette)\n",
    "\n",
    "plot_reg(X, optimized_params, L, ax, color=color, x_extend=x_extend, linestyle='-', X_str=X_str, x_scaler=x_scaler, show_x_scaler=False, linewidth=linewidth, legend=True, alpha=alpha_fit)\n",
    "plot_confidence_intervals(X, opt_params_boot, L, ax, color=color, x_extend=x_extend, x_scaler=x_scaler, alpha=alpha_ci, percentile=95.0, invert_y=True)\n",
    "\n",
    "\n",
    "### Colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap= color_palette, norm=LogNorm())\n",
    "sm.set_clim(df_plot['n_samples_seen'].min(), df_plot['n_samples_seen'].max())\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label('Number of Samples Seen')\n",
    "cbar.set_label('Number of Samples Seen', rotation=270, labelpad=15)\n",
    "\n",
    "\n",
    "### Formatting\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('FLOPs')\n",
    "ax.set_ylabel('Alignment')\n",
    "ax.set_xlabel('Total Flops (C)', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Alignment Score (S)', fontsize=16, fontweight='bold')\n",
    "ax.set_title('SimCLR Training', fontsize=20, fontweight='bold')\n",
    "ax.grid(False)\n",
    "ax = set_ticks(ax, xticks_mode='log', yticks_mode=None, yticks=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# handles, labels = handles[-7:], labels[-7:]\n",
    "# handles, labels = handles[-2:], labels[-2:]\n",
    "handles, labels = handles[-1:], labels[-1:]\n",
    "ax.legend(handles, labels, loc='lower right')\n",
    "# ax.legend().remove()\n",
    "\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# figures_dir = '../figures'\n",
    "# fig_name = 'fig7_simclr'\n",
    "# formats = ['pdf', 'png', 'svg']\n",
    "# save_figs(figures_dir, fig_name, formats=formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_extend = 1.1\n",
    "X_str = r'$$\\tilde{C}$$'\n",
    "linewidth = 3.0\n",
    "alpha_scatter = 0.2\n",
    "alpha_scatter = 1\n",
    "alpha_ci = 0.2\n",
    "alpha_fit = 1.0\n",
    "fig_multiplier = 0.75\n",
    "figsize = (24, 12)\n",
    "figsize = (fig_multiplier * figsize[0], fig_multiplier * figsize[1])\n",
    "\n",
    "color_palette_models = COLOR_PALETTES['models']\n",
    "color_palette_regions = COLOR_PALETTES['regions']\n",
    "color_1, color_2 = color_palette_regions[0], color_palette_regions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionNames = {\n",
    "    'v1': 'V1',\n",
    "    'v2': 'V2',\n",
    "    'v4': 'V4',\n",
    "    'it': 'IT',\n",
    "    'behavior': 'Behavioral',\n",
    "    'avg': 'Average',\n",
    "    # 'neuro': 'Neural',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=figsize, dpi=300)\n",
    "for idx, reg in enumerate(regionNames.keys()):\n",
    "    ax = axes.flatten()[idx]\n",
    "\n",
    "    ### Group 11\n",
    "    exp_name = f'{reg}'\n",
    "    \n",
    "    \n",
    "    df_region = all_df[exp_name]\n",
    "    optimized_params_neuro = optimized_params_dict[exp_name]\n",
    "    opt_params_boot_neuro = opt_params_boot_dict[exp_name]\n",
    "    L = LOSS_FUNCTIONS[L_viz_dict[exp_name]]\n",
    "    x_scaler = x_scale_dict[exp_name]\n",
    "    X = df_region.total_flops.values / x_scaler\n",
    "    \n",
    "    color = color_2\n",
    "    sns.scatterplot(data=df_region, x='total_flops', y='score', ax=ax, color=color, alpha=alpha_scatter)\n",
    "    plot_reg(X, optimized_params_neuro, L, ax, color=color, x_extend=x_extend, linestyle='-', X_str=X_str, x_scaler=x_scaler, show_x_scaler=False, linewidth=linewidth, legend=False, alpha=alpha_fit)\n",
    "    plot_confidence_intervals(X, opt_params_boot_neuro, L, ax, color=color, x_scaler=x_scaler, alpha=alpha_ci, percentile=95.0, invert_y=True)\n",
    "\n",
    "\n",
    "    ### Formatting\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    ax.set_xlabel('FLOPs')\n",
    "    ax.set_ylabel('Alignment')\n",
    "    ax.set_xlabel('Total Flops (C)', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel('Alignment Score (S)', fontsize=16, fontweight='bold')\n",
    "    ax.set_title(regionNames[reg], fontsize=20, fontweight='bold')\n",
    "    ax = set_ticks(ax, xticks_mode='log', yticks_mode=None, yticks=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "\n",
    "    ### Legend\n",
    "    # handles, labels = ax.get_legend_handles_labels()\n",
    "    # labels = [\n",
    "    #     'Strong Prior  ' + labels[0],\n",
    "    #     'Weak Prior '  + labels[1]\n",
    "    # ]\n",
    "    # ax.legend(handles, labels, fontsize=12)\n",
    "    plt.suptitle('SimCLR Training - Regions', fontsize=24, fontweight='bold')\n",
    "    \n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "    \n",
    "    \n",
    "ax = axes.flatten()[-1]\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "figures_dir = '../figures'\n",
    "fig_name = 'fig13_simclr_regions'\n",
    "formats = ['pdf', 'png', 'svg']\n",
    "save_figs(figures_dir, fig_name, formats=formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
