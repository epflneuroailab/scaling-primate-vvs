{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pickle\n",
    "from itertools import product\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.set_theme(style='ticks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = Path('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(repo_dir) not in sys.path:\n",
    "    sys.path.append(str(repo_dir))\n",
    "    \n",
    "from analysis.curve_fitting.src.fitting_functions import LOSS_FUNCTIONS\n",
    "from analysis.curve_fitting.src.utils import apply_filters, load_yaml, convert_loss_parameters, convert_loss_parameters_batch\n",
    "\n",
    "from visualization.src.utils import COLOR_PALETTES, set_ticks, save_figs, COLORS\n",
    "from visualization.src.visualize import plot_reg, plot_reg_bivariate, plot_confidence_intervals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'results_csv': repo_dir / 'results' / 'benchmark_scores.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_csv = args['results_csv']\n",
    "\n",
    "df_results = pd.read_csv(results_csv)\n",
    "\n",
    "df_results.arch_family.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_adv = {\n",
    "    'data_filters': {\n",
    "        'set_filters': {\n",
    "            'region': [\n",
    "                'V1',\n",
    "                'V2',\n",
    "                'V4',\n",
    "                'IT',\n",
    "                'Behavioral'\n",
    "                ],\n",
    "            'dataset': [\n",
    "                'imagenet',\n",
    "                ],\n",
    "            'adv_method': [\n",
    "                'ffgsm_eps-1_alpha-125-ep10',\n",
    "                ],\n",
    "            },\n",
    "            \n",
    "    'boolean_filters': {\n",
    "        'equals_false': [\n",
    "            'is_pretrained',\n",
    "            'is_random',\n",
    "            'is_ssl',\n",
    "            'is_ablation'\n",
    "            ],\n",
    "        'equals_true': [\n",
    "            'is_adv',\n",
    "            ]\n",
    "        },\n",
    "    \n",
    "    'group_by': {\n",
    "        'avg_score': {\n",
    "            'keys': [\n",
    "                'model_id',\n",
    "                'arch',\n",
    "                'dataset',\n",
    "                'flops',\n",
    "                'n_params',\n",
    "                'n_samples',\n",
    "                'n_samples_seen',\n",
    "                'total_flops',\n",
    "                'arch_family',\n",
    "                'samples_per_class',\n",
    "                'adv_method',\n",
    "\n",
    "            ],\n",
    "            'reduce': {'score': 'mean'}}},\n",
    "\n",
    "    'combine_arch_families': True,\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = repo_dir / 'analysis'\n",
    "config_dir = analysis_dir / 'curve_fitting/configs/adv'\n",
    "config_dir = analysis_dir / 'curve_fitting/configs/model/resnet'\n",
    "results_dir = analysis_dir / 'curve_fitting/outputs/fitting_results'\n",
    "results_dir = analysis_dir / 'curve_fitting/outputs/fitting_results_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"adv_scaling\"\n",
    "experiment_name = \"resnet_avg\"\n",
    "config_nonadv = load_yaml(config_dir / f'{experiment_name}.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_fit = config_nonadv['fitting_parameters']['loss_function']\n",
    "L_viz = config_nonadv['visualization']['loss_function']\n",
    "x_scaler = float(config_nonadv['fitting_parameters']['X_scaler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Data Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv = apply_filters(df_results, config_adv.get('data_filters', {}))\n",
    "df_adv['total_flops'] = 3 * df_adv['flops'] * df_adv['n_samples'] * 10 + 3 * ( df_adv['flops'] ) * 100 * 1281167 \n",
    "df_adv['n_samples_seen'] = df_adv['n_samples_seen'] + 100*df_adv['n_samples']\n",
    "df_adv['is_adv'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_nonadv['data_filters']['combine_arch_families'] = False\n",
    "\n",
    "df_nonadv = apply_filters(df_results, config_nonadv.get('data_filters', {}))\n",
    "df_nonadv['is_adv'] = False\n",
    "df_nonadv.arch.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config3 = {\n",
    "#     'data_filters': {\n",
    "#         'set_filters': {\n",
    "#             'region': [\n",
    "#                 'V1',\n",
    "#                 'V2',\n",
    "#                 'V4',\n",
    "#                 'IT',\n",
    "#                 'Behavioral'\n",
    "#                 ],\n",
    "#             'dataset': [\n",
    "#                 'imagenet',\n",
    "#                 ],\n",
    "#             'arch_family': [\n",
    "#                 'ResNet',\n",
    "#                 ],\n",
    "#             },\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# df_scratch = apply_filters(df_results, config3.get('data_filters', {}))\n",
    "\n",
    "# df_scratch.adv_method.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scratch = df_scratch[df_scratch.adv_method.isin([\n",
    "#     'scratch-ffgsm_eps-1_alpha-125_lr-01',\n",
    "#     'scratch-ffgsm_eps-2_alpha-25_lr-01',\n",
    "#     'scratch-ffgsm_eps-4_alpha-5_lr-01',\n",
    "# ])]\n",
    "\n",
    "# df_scratch['total_flops'] = df_scratch['flops'] * df_scratch['n_samples'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i for i in df_results[df_results.is_adv].model_id.unique() if 'scratch' in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fitting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_dir / f'model_{experiment_name}' / 'results.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "\n",
    "optimized_params = convert_loss_parameters(results['optimized_parameters'], L_fit, L_viz)\n",
    "\n",
    "# Convert bootstrapped parameters\n",
    "opt_params_boot = results['optimized_parameters_bootstrapped']\n",
    "opt_params_boot = convert_loss_parameters_batch(\n",
    "    params=opt_params_boot,\n",
    "    src_loss=L_fit,\n",
    "    dst_loss=L_viz\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_extend = 1.1\n",
    "x_extend = 10\n",
    "X_str = r'$$\\tilde{N}$$'\n",
    "linewidth = 3.0\n",
    "alpha_scatter = 1.0\n",
    "alpha_ci = 0.2\n",
    "alpha_fit = 1.0\n",
    "fig_multiplier = 0.7\n",
    "figsize = (10, 6)\n",
    "figsize = (fig_multiplier * figsize[0], fig_multiplier * figsize[1])\n",
    "\n",
    "color_palette = COLOR_PALETTES['models']\n",
    "color = \"#023e8a\"\n",
    "color_palette = [color_palette[0], color_palette[-1]]\n",
    "\n",
    "\n",
    "\n",
    "L = LOSS_FUNCTIONS[L_viz]\n",
    "X = df_nonadv.total_flops.values / x_scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_adv, df_nonadv]).reset_index(drop=True)\n",
    "\n",
    "model_sort = {\n",
    "    'resnet18': 0,\n",
    "    'resnet34': 1,\n",
    "    'resnet50': 2,\n",
    "    'resnet101': 3,\n",
    "    'resnet152': 4,\n",
    "}\n",
    "df_concat['sort'] = df_concat['arch'].map(model_sort)\n",
    "df_concat = df_concat.sort_values('sort').reset_index(drop=True)\n",
    "\n",
    "model_name_map = {\n",
    "    'resnet18': 'ResNet-18',\n",
    "    'resnet34': 'ResNet-34',\n",
    "    'resnet50': 'ResNet-50',\n",
    "    'resnet101': 'ResNet-101',\n",
    "    'resnet152': 'ResNet-152',\n",
    "}\n",
    "df_concat = df_concat.replace({'arch': model_name_map})\n",
    "df_concat['Adversarially Finetuned'] = df_concat['is_adv']\n",
    "df_concat['Model'] = df_concat['arch']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_concat = pd.concat([df, df_nonadv, df_scratch]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=figsize, dpi=300)\n",
    "\n",
    "ax = axes\n",
    "\n",
    "df_plot = df_concat\n",
    "\n",
    "# df_plot = df_concat.groupby(['model_id', 'total_flops', 'arch', 'n_samples', 'n_samples_seen', 'n_params', 'arch_family', 'is_adv']).agg({'score':'mean'}).reset_index()\n",
    "# sns.scatterplot(data=df_plot, x='total_flops', y='score', style='arch', hue='is_adv', ax=ax, s=120, palette=color_palaette)\n",
    "sns.scatterplot(data=df_plot, x='total_flops', y='score', style='Model', hue='Adversarially Finetuned', ax=ax, s=120, palette=color_palette)\n",
    "\n",
    "\n",
    "plot_reg(X, optimized_params, L, ax, color=color, x_extend=x_extend, linestyle='-', X_str=X_str, x_scaler=x_scaler, show_x_scaler=False, linewidth=linewidth, legend=True, alpha=alpha_fit)\n",
    "plot_confidence_intervals(X, opt_params_boot, L, ax, color=color, x_extend=x_extend, x_scaler=x_scaler, alpha=alpha_ci, percentile=95.0, invert_y=True)\n",
    "\n",
    "\n",
    "\n",
    "### Formatting\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('FLOPs')\n",
    "ax.set_ylabel('Alignment')\n",
    "ax.set_xlabel('Total Flops (C)', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Alignment Score (S)', fontsize=16, fontweight='bold')\n",
    "ax.set_title('Adversarial Finetuning', fontsize=20, fontweight='bold')\n",
    "ax.grid(False)\n",
    "ax = set_ticks(ax, xticks_mode='log', yticks_mode=None, yticks=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "\n",
    "\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# handles, labels = handles[-7:], labels[-7:]\n",
    "# ax.legend(handles, labels, loc='lower right')\n",
    "# ax.legend().remove()\n",
    "\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "figures_dir = '../figures'\n",
    "fig_name = 'fig7_adv'\n",
    "formats = ['pdf', 'png', 'svg']\n",
    "save_figs(figures_dir, fig_name, formats=formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_extend = 1.1\n",
    "X_str = r'$$\\tilde{C}$$'\n",
    "linewidth = 3.0\n",
    "alpha_scatter = 0.2\n",
    "alpha_scatter = 1\n",
    "alpha_ci = 0.2\n",
    "alpha_fit = 1.0\n",
    "fig_multiplier = 0.75\n",
    "figsize = (24, 12)\n",
    "figsize = (fig_multiplier * figsize[0], fig_multiplier * figsize[1])\n",
    "\n",
    "color_palette_models = COLOR_PALETTES['models']\n",
    "color_palette_regions = COLOR_PALETTES['regions']\n",
    "color_1, color_2 = color_palette_models[0], color_palette_models[-1]\n",
    "color_1, color_2 = color_palette_regions[0], color_palette_regions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionNames = {\n",
    "    'v1': 'V1',\n",
    "    'v2': 'V2',\n",
    "    'v4': 'V4',\n",
    "    'it': 'IT',\n",
    "    'behavior': 'Behavioral',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_nonadv2 = copy.deepcopy(config_nonadv)\n",
    "config_nonadv2['data_filters']['group_by'] = {}\n",
    "df_nonadv2 = apply_filters(df_results, config_nonadv2.get('data_filters', {}))\n",
    "\n",
    "\n",
    "config_adv2 = copy.deepcopy(config_adv)\n",
    "config_adv2['data_filters']['group_by'] = {}\n",
    "df_adv2 = apply_filters(df_results, config_adv2.get('data_filters', {}))\n",
    "\n",
    "df_adv2['total_flops'] = 3 * df_adv2['flops'] * df_adv2['n_samples'] * 10 + 3 * ( df_adv2['flops'] ) * 100 * 1281167\n",
    "df_adv2['n_samples_seen'] = df_adv2['n_samples_seen'] + 100*df_adv2['n_samples']\n",
    "\n",
    "df_adv2['is_adv'] = True\n",
    "df_nonadv2['is_adv'] = False\n",
    "df_concat2 = pd.concat([df_adv2, df_nonadv2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=figsize, dpi=300)\n",
    "for idx, reg in enumerate(regionNames.keys()):\n",
    "    ax = axes.flatten()[idx]\n",
    "\n",
    "    ### Group 11\n",
    "    exp_name = f'{reg}_group1'\n",
    "    \n",
    "    df_region = df_concat2[df_concat2.region == regionNames[reg]].copy()\n",
    "    \n",
    "    # df_region = all_df[exp_name]\n",
    "    # optimized_params_neuro = optimized_params_dict[exp_name]\n",
    "    # opt_params_boot_neuro = opt_params_boot_dict[exp_name]\n",
    "    # L = LOSS_FUNCTIONS[L_viz_dict[exp_name]]\n",
    "    # x_scaler = x_scale_dict[exp_name]\n",
    "    # X = df_region.total_flops.values / x_scaler\n",
    "    \n",
    "    color = color_1\n",
    "    sns.scatterplot(data=df_region, x='total_flops', y='score', ax=ax, hue='is_adv', alpha=alpha_scatter, palette=color_palette)\n",
    "    # plot_reg(X, optimized_params_neuro, L, ax, color=color, x_extend=x_extend, linestyle='-', X_str=X_str, x_scaler=x_scaler, show_x_scaler=False, linewidth=linewidth, legend=False, alpha=alpha_fit)\n",
    "    # plot_confidence_intervals(X, opt_params_boot_neuro, L, ax, color=color, x_scaler=x_scaler, alpha=alpha_ci, percentile=95.0, invert_y=True)\n",
    "\n",
    "\n",
    "    ### Formatting\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('FLOPs')\n",
    "    ax.set_ylabel('Alignment')\n",
    "    ax.set_xlabel('Total Flops (C)', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel('Alignment Score (S)', fontsize=16, fontweight='bold')\n",
    "    ax.set_title(regionNames[reg], fontsize=20, fontweight='bold')\n",
    "    # ax = set_ticks(ax, xticks_mode='log', yticks_mode=None, yticks=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "\n",
    "\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "    \n",
    "    \n",
    "ax = axes.flatten()[-1]\n",
    "\n",
    "\n",
    "\n",
    "df_region = df_concat2.groupby(['model_id', 'total_flops', 'arch', 'n_samples', 'is_adv']).agg({'score':'mean'}).copy()\n",
    "\n",
    "# df_region = all_df[exp_name]\n",
    "# optimized_params_neuro = optimized_params_dict[exp_name]\n",
    "# opt_params_boot_neuro = opt_params_boot_dict[exp_name]\n",
    "# L = LOSS_FUNCTIONS[L_viz_dict[exp_name]]\n",
    "# x_scaler = x_scale_dict[exp_name]\n",
    "# X = df_region.total_flops.values / x_scaler\n",
    "\n",
    "color = color_1\n",
    "sns.scatterplot(data=df_region, x='total_flops', y='score', hue='is_adv', ax=ax, alpha=alpha_scatter, palette=color_palette)\n",
    "# plot_reg(X, optimized_params_neuro, L, ax, color=color, x_extend=x_extend, linestyle='-', X_str=X_str, x_scaler=x_scaler, show_x_scaler=False, linewidth=linewidth, legend=False, alpha=alpha_fit)\n",
    "# plot_confidence_intervals(X, opt_params_boot_neuro, L, ax, color=color, x_scaler=x_scaler, alpha=alpha_ci, percentile=95.0, invert_y=True)\n",
    "\n",
    "\n",
    "### Formatting\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('FLOPs')\n",
    "ax.set_ylabel('Alignment')\n",
    "ax.set_xlabel('Total Flops (C)', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Alignment Score (S)', fontsize=16, fontweight='bold')\n",
    "ax.set_title('Average', fontsize=20, fontweight='bold')\n",
    "# ax = set_ticks(ax, xticks_mode='log', yticks_mode=None, yticks=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "\n",
    "### Legend\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# labels = [\n",
    "#     'Strong Prior  ' + labels[0],\n",
    "#     'Weak Prior '  + labels[1]\n",
    "# ]\n",
    "# ax.legend(handles, labels, fontsize=12)\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "# figures_dir = '../figures'\n",
    "# fig_name = 'fig5_regions_compare'\n",
    "# formats = ['pdf', 'png', 'svg']\n",
    "# save_figs(figures_dir, fig_name, formats=formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
