# Model
arch: convnext_small
drop_path_rate: 0.4
device: 'gpu'
layer_scale_init_value: 1e-6
layer_decay: 1.0
head_init_scale: 1.0
compile_mode: 'default'

# Optimizer & LR scheme
loss_fn: 'cross_entropy'
max_duration: '100ep'
batch_size: 256
opt: 'adamw'
lr: 4e-3
min_lr: 1e-6
lr_scheduler: 'cosineannealinglrwithwarmup'
lr_warmup_duration: '20ep'
weight_decay: 0.05
opt_betas: [0.9, 0.999]
opt_eps: 1e-8
# clip_grad: None
label_smoothing: 0
accumulation_steps: 1
target_batch_size: 4096


# Data
data_path: '/mnt/scratch/akgokce/datasets/imagenet/'
workers: 10
pin_memory: True
train_samples: 0
seed: 0

# Resizing
val_resize_size: 256
val_crop_size: 224
train_crop_size: 224

# Misc
disable_progress_bar: False
lr_monitor: False
log_interval: "1ba"

# Logging
eval_interval: '1ep'
wandb_project: 'scalingLaws'
wandb_entity: 'akgokce'
save_dir: '/mnt/scratch/akgokce/brain/outputs2/'
run_name: convnext_small_imagenet_full-v1

