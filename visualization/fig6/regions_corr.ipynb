{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pickle\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = Path('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(repo_dir) not in sys.path:\n",
    "    sys.path.append(str(repo_dir))\n",
    "    \n",
    "from analysis.curve_fitting.src.fitting_functions import LOSS_FUNCTIONS\n",
    "from analysis.curve_fitting.src.utils import apply_filters, load_yaml, convert_loss_parameters, convert_loss_parameters_batch\n",
    "\n",
    "from visualization.src.utils import COLOR_PALETTES, set_ticks, save_figs\n",
    "from visualization.src.visualize import plot_reg, plot_reg_bivariate, plot_confidence_intervals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'results_csv': repo_dir / 'results' / 'benchmark_scores_local.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_csv = args['results_csv']\n",
    "\n",
    "df_results = pd.read_csv(results_csv)\n",
    "df_results['total_flops'] = df_results['flops'] * df_results['n_samples_seen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = repo_dir / 'analysis'\n",
    "config_dir = analysis_dir / 'curve_fitting/configs/region'\n",
    "results_dir = analysis_dir / 'curve_fitting/fitting_results'\n",
    "# results_dir = analysis_dir / 'curve_fitting/fitting_results_region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_filters': {\n",
    "        'set_filters': {\n",
    "            'region': [\n",
    "                'V1',\n",
    "                'V2',\n",
    "                'V4',\n",
    "                'IT',\n",
    "                'Behavioral'\n",
    "                ],\n",
    "            'dataset': [\n",
    "                'imagenet',\n",
    "                'ecoset',\n",
    "                ]\n",
    "            },\n",
    "    'boolean_filters': {\n",
    "        'equals_false': [\n",
    "            'is_pretrained',\n",
    "            'is_random',\n",
    "            'is_ssl',\n",
    "            'is_adv',\n",
    "            'is_ablation'\n",
    "            ]\n",
    "        },\n",
    "    \n",
    "    # 'group_by': {\n",
    "    #     'avg_score': {\n",
    "    #         'keys': [\n",
    "    #             'model_id',\n",
    "    #             'arch',\n",
    "    #             'dataset',\n",
    "    #             'flops',\n",
    "    #             'n_params',\n",
    "    #             'n_samples',\n",
    "    #             'n_samples_seen',\n",
    "    #             'total_flops',\n",
    "    #             'arch_family',\n",
    "    #             'samples_per_class',\n",
    "    #             'benchmark_name',\n",
    "    #             'region'\n",
    "    #         ],\n",
    "    #         'reduce': {'score': 'mean'}}},\n",
    "    # 'arch_families_samples': {\n",
    "    #     'arch_family': [\n",
    "    #         'ConvNeXt',\n",
    "    #         'ConvNeXtFlex',\n",
    "    #         'ViT',\n",
    "    #         'ViTFlex',\n",
    "    #         ],\n",
    "    # 'samples_per_class': [0, 300]},\n",
    "    'combine_arch_families': True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Data Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_filters(df_results, config['data_filters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "num_bootstraps = 1000\n",
    "fraction = 1\n",
    "\n",
    "rng = np.random.default_rng(random_state)\n",
    "all_samples = int(len(df)/5)\n",
    "num_samples = int(fraction * all_samples)\n",
    "random_indices = rng.integers(0, all_samples, size=(num_bootstraps, num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fits = []\n",
    "\n",
    "for i, region in tqdm(enumerate(['V1', 'V2', 'V4', 'IT', 'Behavioral']), total=5):\n",
    "    for j, indices in tqdm(enumerate(random_indices), leave=False, total=num_bootstraps):\n",
    "        data = df[df.region == region].copy().reset_index(drop=True)\n",
    "        data = data.iloc[indices]\n",
    "        \n",
    "        x = data['acc']\n",
    "        y = data['score']\n",
    "        reg = stats.linregress(x, y)\n",
    "        df_fits.append({\n",
    "            'region': region,\n",
    "            'slope': reg.slope,\n",
    "            'intercept': reg.intercept,\n",
    "            'rvalue': reg.rvalue,\n",
    "            'pvalue': reg.pvalue,\n",
    "            'stderr': reg.stderr,\n",
    "        })\n",
    "        \n",
    "df_fits = pd.DataFrame(df_fits)\n",
    "df_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data = data.groupby(['model_id', 'acc']).agg({'score': 'mean'}).reset_index()\n",
    "x = data['acc']\n",
    "y = data['score']\n",
    "reg = stats.linregress(x, y)\n",
    "avg_r = reg.rvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier = 1.1\n",
    "X_str = r'$$\\tilde{C}$$'\n",
    "linewidth = 3.0\n",
    "alpha_scatter = 0.2\n",
    "alpha_ci = 0.2\n",
    "alpha_fit = 1.0\n",
    "fig_multiplier = 0.75\n",
    "fig_multiplier = 0.6\n",
    "fig_multiplier = 0.5\n",
    "figsize = (10, 8)\n",
    "figsize = (fig_multiplier * figsize[0], fig_multiplier * figsize[1])\n",
    "\n",
    "color_palette_regions = COLOR_PALETTES['regions']\n",
    "color_palette_samples = COLOR_PALETTES['samples']\n",
    "color_1, color_2 = color_palette_regions[0], color_palette_regions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neuro = df.groupby(['model_id', 'arch_family', 'n_samples_seen', 'acc']).agg({'score': 'mean'}).reset_index()\n",
    "df_behav = df[df.region == 'Behavioral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_order = {\n",
    "    'AlexNet': 0,\n",
    "    'ConvNeXt': 1,\n",
    "    'CORnet-S': 2,\n",
    "    'ViT': 3,\n",
    "    'EfficientNet': 4,\n",
    "    'ResNet': 5,\n",
    "}\n",
    "\n",
    "df_neuro['arch_order'] = df_neuro['arch_family'].map(arch_order)\n",
    "df_neuro = df_neuro.sort_values('arch_order')\n",
    "\n",
    "df_behav['arch_order'] = df_behav['arch_family'].map(arch_order)\n",
    "df_behav = df_behav.sort_values('arch_order')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=figsize, dpi=300)\n",
    "ax = axes\n",
    "\n",
    "data_region = df_neuro.copy()\n",
    "# data_region.sort_values(['arch_family'], inplace=True)\n",
    "sns.scatterplot(data=data_region, x='acc', y='score', hue='n_samples_seen', hue_norm=LogNorm(), ax=ax, markers=True, style='arch_family', s=100, alpha=0.8, palette=color_palette_samples)\n",
    "\n",
    "\n",
    "# Set the labels\n",
    "ax.set_ylabel('Neural Alignment', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Validation Accuracy', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Set the ticks\n",
    "ax.grid(which='minor', alpha=0.2)\n",
    "ax.grid(which='major', alpha=0.8)\n",
    "ax.grid(True)\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "### Legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "handles, labels = handles[-6:], labels[-6:]\n",
    "ax.legend(handles=handles, labels=labels, loc='lower right')\n",
    "\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('../figures/regions_compare.svg', bbox_inches='tight')\n",
    "\n",
    "figures_dir = '../figures'\n",
    "fig_name = 'fig6_corr_neuro'\n",
    "formats = ['pdf', 'png', 'svg']\n",
    "save_figs(figures_dir, fig_name, formats=formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (12, 8)\n",
    "figsize = (fig_multiplier * figsize[0], fig_multiplier * figsize[1])\n",
    "fig, axes = plt.subplots(1, 1, figsize=figsize, dpi=300)\n",
    "ax = axes\n",
    "\n",
    "data_region = df_behav.copy()\n",
    "# data_region.sort_values(['arch_family'], inplace=True)\n",
    "sns.scatterplot(data=data_region, x='acc', y='score', hue='n_samples_seen', hue_norm=LogNorm(), ax=ax, markers=True, style='arch_family', s=100, alpha=0.8, palette=color_palette_samples)\n",
    "\n",
    "### Colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap= color_palette_samples, norm=LogNorm())\n",
    "sm.set_clim(data_region['n_samples_seen'].min(), data_region['n_samples_seen'].max())\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label('Number of Samples Seen')\n",
    "\n",
    "# Set the labels\n",
    "ax.set_ylabel('Behavioral Alignment', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Validation Accuracy', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Set the ticks\n",
    "ax.grid(which='minor', alpha=0.2)\n",
    "ax.grid(which='major', alpha=0.8)\n",
    "ax.grid(True)\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "### Legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "handles, labels = handles[-6:], labels[-6:]\n",
    "ax.legend(handles=handles, labels=labels, loc='lower right')\n",
    "ax.legend().remove()\n",
    "\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('../figures/regions_compare.svg', bbox_inches='tight')\n",
    "\n",
    "\n",
    "figures_dir = '../figures'\n",
    "fig_name = 'fig6_corr_behav'\n",
    "formats = ['pdf', 'png', 'svg']\n",
    "save_figs(figures_dir, fig_name, formats=formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (8, 8)\n",
    "figsize = (fig_multiplier * figsize[0], fig_multiplier * figsize[1])\n",
    "fig, axes = plt.subplots(1, 1, figsize=figsize, dpi=300)\n",
    "ax = axes\n",
    "\n",
    "\n",
    "\n",
    "df_plot = df_fits[df_fits.region != 'Average'].copy()\n",
    "sns.barplot(data=df_plot, hue='region', x='region', y='rvalue', ax=ax, palette=color_palette_regions, errorbar=('ci', 95))\n",
    "\n",
    "### Average\n",
    "ax.axhline(avg_r, 0, 1, linestyle='--', label='Average')\n",
    "ax.text(0.02, avg_r+0.03, \"Average\", transform=ax.get_yaxis_transform())\n",
    "\n",
    "\n",
    "ax.set_xlabel('FLOPs')\n",
    "ax.set_ylabel('Alignment')\n",
    "ax.set_xlabel('Regions', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Correlation', fontsize=16, fontweight='bold')\n",
    "\n",
    "\n",
    "ax.legend().remove()\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "ax.grid(False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "figures_dir = '../figures'\n",
    "fig_name = 'fig6_corr_bar'\n",
    "formats = ['pdf', 'png', 'svg']\n",
    "save_figs(figures_dir, fig_name, formats=formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
