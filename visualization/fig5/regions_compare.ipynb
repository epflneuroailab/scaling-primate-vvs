{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pickle\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = Path('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(repo_dir) not in sys.path:\n",
    "    sys.path.append(str(repo_dir))\n",
    "    \n",
    "from analysis.curve_fitting.src.fitting_functions import LOSS_FUNCTIONS\n",
    "from analysis.curve_fitting.src.utils import apply_filters, load_yaml, convert_loss_parameters, convert_loss_parameters_batch\n",
    "\n",
    "from visualization.src.utils import COLOR_PALETTES, set_ticks, save_figs\n",
    "from visualization.src.visualize import plot_reg, plot_reg_bivariate, plot_confidence_intervals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'results_csv': repo_dir / 'results' / 'benchmark_scores.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_csv = args['results_csv']\n",
    "\n",
    "df_results = pd.read_csv(results_csv)\n",
    "df_results['total_flops'] = df_results['flops'] * df_results['n_samples_seen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = repo_dir / 'analysis'\n",
    "config_dir = analysis_dir / 'curve_fitting/configs/region'\n",
    "results_dir = analysis_dir / 'curve_fitting/fitting_results'\n",
    "# results_dir = analysis_dir / 'curve_fitting/fitting_results_region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = [\n",
    "    'v1',\n",
    "    'v2',\n",
    "    'v4',\n",
    "    'it',\n",
    "    'behavior',\n",
    "    'avg',\n",
    "]\n",
    "\n",
    "model_groups = ['group1', 'group2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_configs = {}\n",
    "\n",
    "for r, g in product(region, model_groups):\n",
    "    yaml_config = config_dir / f'{r}/{r}_{g}.yaml'\n",
    "    all_configs[f\"{r}_{g}\"] = load_yaml(yaml_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_fit_dict = {key: config['fitting_parameters']['loss_function'] for key, config in all_configs.items()}\n",
    "L_viz_dict = {key: config['visualization']['loss_function'] for key, config in all_configs.items()}\n",
    "x_scale_dict = {key: float(config['fitting_parameters']['X_scaler']) for key, config in all_configs.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Data Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = {\n",
    "    name: apply_filters(df_results, config.get('data_filters', {}))\n",
    "    for name, config in all_configs.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fitting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_params_dict = {}\n",
    "opt_params_boot_dict = {}\n",
    "\n",
    "for exp_name in all_configs.keys():\n",
    "    with open(results_dir / f'region_{exp_name}' / 'results.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "\n",
    "    L_fit = L_fit_dict[exp_name]\n",
    "    L_viz = L_viz_dict[exp_name]\n",
    "    optimized_params_dict[exp_name] = convert_loss_parameters(results['optimized_parameters'], L_fit, L_viz)\n",
    "\n",
    "    # Convert bootstrapped parameters\n",
    "    opt_params_boot = results['optimized_parameters_bootstrapped']\n",
    "    opt_params_boot_dict[exp_name] = convert_loss_parameters_batch(\n",
    "        params=opt_params_boot,\n",
    "        src_loss=L_fit,\n",
    "        dst_loss=L_viz\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapped Confidence Intervals for Gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gains = []\n",
    "\n",
    "\n",
    "for exp_name, opt_params_boot in opt_params_boot_dict.items():\n",
    "    reg, model_group = exp_name.split('_')\n",
    "    for opt_params in opt_params_boot:\n",
    "        if model_group == 'group1':\n",
    "            E, A, alpha = opt_params\n",
    "            lambda_ = None\n",
    "        else:\n",
    "            E, A, lambda_, alpha = opt_params\n",
    "        gain = A * 10 ** (alpha)\n",
    "        df_gains.append(\n",
    "            {\n",
    "                'region': reg,\n",
    "                'model_group': model_group,\n",
    "                'E': E,\n",
    "                'A': A,\n",
    "                'lambda': lambda_,\n",
    "                'alpha': alpha,\n",
    "                'gain': gain\n",
    "            }\n",
    "        )\n",
    "\n",
    "df_gains = pd.DataFrame(df_gains)\n",
    "df_gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E, A, alpha = optimized_params_dict['avg_group1']\n",
    "avg_gain_group1 = A * 10 ** (alpha)\n",
    "\n",
    "\n",
    "E, A, lambda_, alpha = optimized_params_dict['avg_group2']\n",
    "avg_gain_group2 = A * 10 ** (alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_extend = 1.1\n",
    "X_str = r'$$\\tilde{C}$$'\n",
    "linewidth = 3.0\n",
    "alpha_scatter = 0.2\n",
    "alpha_ci = 0.2\n",
    "alpha_fit = 1.0\n",
    "fig_multiplier = 0.75\n",
    "figsize = (24, 12)\n",
    "figsize = (fig_multiplier * figsize[0], fig_multiplier * figsize[1])\n",
    "\n",
    "color_palette_models = COLOR_PALETTES['models']\n",
    "color_palette_regions = COLOR_PALETTES['regions']\n",
    "color_1, color_2 = color_palette_models[0], color_palette_models[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionNames = {\n",
    "    'v1': 'V1',\n",
    "    'v2': 'V2',\n",
    "    'v4': 'V4',\n",
    "    'it': 'IT',\n",
    "    'behavior': 'Behavioral',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=figsize, dpi=300)\n",
    "for idx, reg in enumerate(region[:-1]):\n",
    "    ax = axes.flatten()[idx]\n",
    "\n",
    "    ### Group 11\n",
    "    exp_name = f'{reg}_group1'\n",
    "    df_region = all_df[exp_name]\n",
    "    optimized_params_neuro = optimized_params_dict[exp_name]\n",
    "    opt_params_boot_neuro = opt_params_boot_dict[exp_name]\n",
    "    L = LOSS_FUNCTIONS[L_viz_dict[exp_name]]\n",
    "    x_scaler = x_scale_dict[exp_name]\n",
    "    X = df_region.total_flops.values / x_scaler\n",
    "    \n",
    "    color = color_1\n",
    "    sns.scatterplot(data=df_region, x='total_flops', y='score', ax=ax, color=color, alpha=alpha_scatter)\n",
    "    plot_reg(X, optimized_params_neuro, L, ax, color=color, x_extend=x_extend, linestyle='-', X_str=X_str, x_scaler=x_scaler, show_x_scaler=False, linewidth=linewidth, legend=False, alpha=alpha_fit)\n",
    "    plot_confidence_intervals(X, opt_params_boot_neuro, L, ax, color=color, x_scaler=x_scaler, alpha=alpha_ci, percentile=95.0, invert_y=True)\n",
    "\n",
    "    ### Behavioral\n",
    "    exp_name = f'{reg}_group2'\n",
    "    df_region = all_df[exp_name]\n",
    "    optimized_params_behavior = optimized_params_dict[exp_name]\n",
    "    opt_params_boot_behavior = opt_params_boot_dict[exp_name]\n",
    "    L = LOSS_FUNCTIONS[L_viz_dict[exp_name]]\n",
    "    x_scaler = x_scale_dict[exp_name]\n",
    "    X = df_region.total_flops.values / x_scaler\n",
    "    \n",
    "    \n",
    "    color = color_2\n",
    "    sns.scatterplot(data=df_region, x='total_flops', y='score', ax=ax, color=color, alpha=alpha_scatter)\n",
    "    plot_reg(X, optimized_params_behavior, L, ax, color=color, x_extend=x_extend, linestyle='-', X_str=X_str, x_scaler=x_scaler, show_x_scaler=False, linewidth=linewidth, legend=False, alpha=alpha_fit)\n",
    "    plot_confidence_intervals(X, opt_params_boot_behavior, L, ax, color=color, x_scaler=x_scaler, alpha=alpha_ci, percentile=95.0, invert_y=True)\n",
    "\n",
    "\n",
    "    ### Formatting\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    ax.set_xlabel('FLOPs')\n",
    "    ax.set_ylabel('Alignment')\n",
    "    ax.set_xlabel('Total Flops (C)', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel('Alignment Score (S)', fontsize=16, fontweight='bold')\n",
    "    ax.set_title(regionNames[reg], fontsize=20, fontweight='bold')\n",
    "    ax = set_ticks(ax, xticks_mode='log', yticks_mode=None, yticks=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "\n",
    "    ### Legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    labels = [\n",
    "        'Strong Prior  ' + labels[0],\n",
    "        'Weak Prior '  + labels[1]\n",
    "    ]\n",
    "    ax.legend(handles, labels, fontsize=12)\n",
    "\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "    \n",
    "    \n",
    "\n",
    "### Gains\n",
    "ax = axes.flatten()[-1]\n",
    "\n",
    "df_plot = df_gains[df_gains['model_group'] == 'group1']\n",
    "df_plot = df_plot[df_plot['region'] != 'avg']\n",
    "df_plot.region = df_plot.region.map(regionNames)\n",
    "sns.barplot(data=df_plot, hue='region', x='region', y='gain', ax=ax, palette=color_palette_regions, errorbar=('ci', 95))\n",
    "\n",
    "avg = avg_gain_group1\n",
    "ax.axhline(avg, 0, 1, linestyle='--', label='Average')\n",
    "ax.text(0.02, avg+0.03, \"Average\", transform=ax.get_yaxis_transform() )\n",
    "\n",
    "ax.legend().remove()\n",
    "ax.set_xlabel('FLOPs')\n",
    "ax.set_ylabel('Alignment')\n",
    "ax.set_xlabel('Regions', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel(r'Score Gain Coefficient per 10$\\times$ FLOPS', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Gain Coefficient', fontsize=16, fontweight='bold')\n",
    "# ax.set_title('Average', fontsize=20, fontweight='bold')\n",
    "# ax = set_ticks(ax, xticks_mode='linear', yticks_mode=None, yticks=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1])\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "ax.grid(False)\n",
    "\n",
    "ticks = ax.get_xticks()\n",
    "labels = ax.get_xticklabels()\n",
    "ax.set_xticks(ticks, labels, rotation=45, ha='right', rotation_mode='anchor')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "figures_dir = '../figures'\n",
    "fig_name = 'fig5_regions_compare'\n",
    "formats = ['pdf', 'png', 'svg']\n",
    "save_figs(figures_dir, fig_name, formats=formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
